{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING THE NECESSARY PACKAGES AND FUNCTIONS:\n",
    "\n",
    "# generic:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import time \n",
    "\n",
    "# more specific:\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer # Normalize samples individually to unit norm.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler # used to compute stacked percentages barplots\n",
    "import pickle # to save models, for instance LDA outputs\n",
    "\n",
    "# NLP:\n",
    "import spacy # version 2.2.1 \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD # LSA\n",
    "from sklearn.decomposition import NMF # NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation # LDA\n",
    "import pyLDAvis # used to visualize and plot ouptut of LDA\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106873, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>tokenized_descriptions</th>\n",
       "      <th>token_descr_as_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "      <td>['aromas', 'include', 'tropical', 'fruit', 'br...</td>\n",
       "      <td>aromas include tropical fruit broom brimstone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>['ripe', 'fruity', 'smooth', 'structured', 'fi...</td>\n",
       "      <td>ripe fruity smooth structured firm tannins fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>['tart', 'snappy', 'lime', 'flesh', 'rind', 'd...</td>\n",
       "      <td>tart snappy lime flesh rind dominate green pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>['like', 'regular', 'bottling', 'comes', 'roug...</td>\n",
       "      <td>like regular bottling comes rough tannic rusti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>This dry and restrained wine offers spice in p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Trimbach 2012 Gewurztraminer (Alsace)</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Trimbach</td>\n",
       "      <td>['dry', 'restrained', 'offers', 'spice', 'prof...</td>\n",
       "      <td>dry restrained offers spice profusion balanced...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   country                                        description  \\\n",
       "0      0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1      1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2      2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3      4        US  Much like the regular bottling from 2012, this...   \n",
       "4      7    France  This dry and restrained wine offers spice in p...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "4                                 NaN      87   24.0             Alsace   \n",
       "\n",
       "            region_1           region_2    taster_name  \\\n",
       "0               Etna                NaN  Kerin O’Keefe   \n",
       "1                NaN                NaN     Roger Voss   \n",
       "2  Willamette Valley  Willamette Valley   Paul Gregutt   \n",
       "3  Willamette Valley  Willamette Valley   Paul Gregutt   \n",
       "4             Alsace                NaN     Roger Voss   \n",
       "\n",
       "                                               title         variety  \\\n",
       "0                  Nicosia 2013 Vulkà Bianco  (Etna)     White Blend   \n",
       "1      Quinta dos Avidagos 2011 Avidagos Red (Douro)  Portuguese Red   \n",
       "2      Rainstorm 2013 Pinot Gris (Willamette Valley)      Pinot Gris   \n",
       "3  Sweet Cheeks 2012 Vintner's Reserve Wild Child...      Pinot Noir   \n",
       "4              Trimbach 2012 Gewurztraminer (Alsace)  Gewürztraminer   \n",
       "\n",
       "                winery                             tokenized_descriptions  \\\n",
       "0              Nicosia  ['aromas', 'include', 'tropical', 'fruit', 'br...   \n",
       "1  Quinta dos Avidagos  ['ripe', 'fruity', 'smooth', 'structured', 'fi...   \n",
       "2            Rainstorm  ['tart', 'snappy', 'lime', 'flesh', 'rind', 'd...   \n",
       "3         Sweet Cheeks  ['like', 'regular', 'bottling', 'comes', 'roug...   \n",
       "4             Trimbach  ['dry', 'restrained', 'offers', 'spice', 'prof...   \n",
       "\n",
       "                               token_descr_as_string  \n",
       "0  aromas include tropical fruit broom brimstone ...  \n",
       "1  ripe fruity smooth structured firm tannins fil...  \n",
       "2  tart snappy lime flesh rind dominate green pin...  \n",
       "3  like regular bottling comes rough tannic rusti...  \n",
       "4  dry restrained offers spice profusion balanced...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winedata = pd.read_csv('../data/winedata_processed_and_tokenized.csv')\n",
    "print(winedata.shape)\n",
    "winedata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wines(wine_indexes):\n",
    "    \"\"\"\n",
    "        a generic function to print the most important feature of a or several wine(s).\n",
    "        from their index(es): ! wine_indexes must be a list\n",
    "    \"\"\"\n",
    "    # print most important characteristic of wine(s),\n",
    "    # from their index(es).\n",
    "    # ! wine_indexes must be a list\n",
    "    for index_ in wine_indexes:\n",
    "        current_wine = winedata.loc[index_, :]\n",
    "        print(current_wine[['title', 'country', 'province', 'region_1', 'variety', 'taster_name']])\n",
    "        print('desciption: ', current_wine.description)\n",
    "        print('tokens: ', current_wine.tokenized_descriptions)\n",
    "        print('------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Vectorization took 2.8347349166870117 seconds.\n"
     ]
    }
   ],
   "source": [
    "# vectorization using BoW :\n",
    "time0 = time.time()\n",
    "\n",
    "# note: we only keep 2000 features:\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1,1), # 1-gram\n",
    "                               max_df=0.95, # ignore t that have a df higher than max_df (corpus-specific stopwords)\n",
    "                               min_df=10, # ignore terms that have a doc freq lower than threshold.\n",
    "                               max_features=2000, # max number of features\n",
    "                              )\n",
    "# Applying the vectorizer on the \"clean\" descriptions:\n",
    "wine_bow = bow_vectorizer.fit_transform(winedata.token_descr_as_string)\n",
    "\n",
    "# list of features\n",
    "terms = bow_vectorizer.get_feature_names()\n",
    "\n",
    "# store the features in a dataframe:\n",
    "bow_features = pd.DataFrame(wine_bow.toarray(), columns=terms)\n",
    "\n",
    "print('Done! Vectorization took', time.time()-time0, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_specific_stopwords = ['$', ' ', '’s', 'wine', 'winemaker', 'winemaking', 'winery',\n",
    "                             'château', 'village', 'domaine',\n",
    "                             'côte', 'saint', 'village', 'parcel', 'parcels',\n",
    "                             'I', 'flavors', 'vineyard', 'vintage',\n",
    "                             'now-2015', 'now-2018', 'now-2025']\n",
    "# Other potential words to consider removing:\n",
    "# douro, nacional, widely, muscat, willamette, bordeaux, pommard, rioja, barbaresco, chianti...\n",
    "\n",
    "# a list of all wine varieties. this is not perfect as some varieties are compound words. But it's a start.\n",
    "variety_stopwords = winedata.variety.unique().tolist()\n",
    "variety_stopwords = [str(variety).lower() for variety in variety_stopwords] # convert to lowercase\n",
    "# we add some notable varieties to the list:\n",
    "variety_stopwords = variety_stopwords + ['pinot', 'gris', 'noir', 'grigio', 'cabernet', \n",
    "                                         'cabernets', 'sauvignon', 'sirah', 'tempranillo', \n",
    "                                         'chenin', 'sangiovese', 'grüner', 'veltliner', 'corvina', \n",
    "                                         'rondinella', 'molinara', 'franc', 'blanc', 'blend',\n",
    "                                         'franc', 'mourvèdre']\n",
    "\n",
    "# a list of all wine provinces. \n",
    "province_stopwords = winedata.province.unique().tolist()\n",
    "province_stopwords = [str(province).lower() for province in province_stopwords] # convert to lowercase\n",
    "# we add some notable province-related words to the list:\n",
    "province_stopwords = province_stopwords + ['france', 'sicily', 'sardinia', 'mendoza', 'spain', \n",
    "                                           'australia', 'italy', 'loire', 'beaujolais']\n",
    "\n",
    "# Standard model used for tokenization.\n",
    "# When using another model, we will have to load it and redefine \"nlp\"\n",
    "\n",
    "# We do not need word vectors here, so we can upload the small English model from spaCy:\n",
    "# We do not need PoS tags, dependencies or named entities, so we disable them (run faster!):\n",
    "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\n",
    "\n",
    "def tokenize_and_clean(description):\n",
    "    \"\"\"\n",
    "        Our basic tokenizer function. It takes as input:\n",
    "            - a pd.Series of the descriptions\n",
    "            - a nlp model\n",
    "        After tokenizing, it cleans the data too,\n",
    "        and returns a list of tokens. \n",
    "    \"\"\"\n",
    "    \n",
    "#     # eventually clean the description with regular expressions here:\n",
    "#     pattern = \"[\\[].*?[\\]]\" # an example of an regex\n",
    "#     description = re.sub(pattern, \"\", description) # remove this pattern from description.\n",
    "\n",
    "    # Tokenize:\n",
    "    mytokens = nlp(description)\n",
    "\n",
    "    # Removing stopwords, punctuation, numbers and convert to lower_case\n",
    "    mytokens = [token.lower_ for token in mytokens if not token.is_punct and not token.is_stop and not token.like_num and not token.is_digit]\n",
    "    \n",
    "    # remove domain-specific stopwords:\n",
    "    mytokens = [token for token in mytokens if token not in domain_specific_stopwords]\n",
    "            \n",
    "    # remove wine variety occurrences in the descriptions:\n",
    "    mytokens = [token for token in mytokens if token not in variety_stopwords]\n",
    "    \n",
    "    # remove wine province occurrences in the descriptions:\n",
    "    mytokens = [token for token in mytokens if token not in province_stopwords]\n",
    "                \n",
    "    # Return preprocessed list of tokens\n",
    "    return mytokens\n",
    "\n",
    "def concatenate_list_of_words_in_one_string(list_of_words):\n",
    "    \"\"\"\n",
    "        build one string with a list of words, with a space in the middle\n",
    "    \"\"\"\n",
    "    return \" \".join(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f7d49c2f3b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_and_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetwine1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tokenize and clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate_list_of_words_in_one_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need 1 string as input to BoW vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtarget1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtarget1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_doc_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 1075\u001b[0;31m                     \"max_df corresponds to < documents than min_df\")\n\u001b[0m\u001b[1;32m   1076\u001b[0m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[1;32m   1077\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "# targetwine1 = winedata.iloc[14,:] # this wine is the input to the recommender system\n",
    "# target1 = tokenize_and_clean(targetwine1.description) # tokenize and clean\n",
    "# target1 = concatenate_list_of_words_in_one_string(target1) # need 1 string as input to BoW vectorizer\n",
    "# target1 = bow_vectorizer.fit_transform([target1])\n",
    "# target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106873, 2000)\n",
      "(106872, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10       0\n",
       "2015     0\n",
       "2016     0\n",
       "2017     0\n",
       "2018     0\n",
       "        ..\n",
       "zest     0\n",
       "zesty    0\n",
       "zin      0\n",
       "zingy    0\n",
       "zippy    0\n",
       "Name: 14, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_vectors = bow_features.copy()\n",
    "target1 = wine_vectors.iloc[14,:]\n",
    "print(wine_vectors.shape)\n",
    "wine_vectors.drop(14, inplace=True)\n",
    "print(wine_vectors.shape)\n",
    "target1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity of target with full vectorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7a86104d48b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_array'"
     ]
    }
   ],
   "source": [
    "cos_sim = cosine_similarity(target1.values.reshape(-1, 1), bow_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
