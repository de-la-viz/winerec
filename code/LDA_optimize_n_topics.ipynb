{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the Number of Topics for LDA\n",
    "\n",
    "We harness the power of data visualization and use the package pyLDAvis for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import time # will be use to choose the faster solution\n",
    "\n",
    "# to visualize LDA topics\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle # to save models, for instance LDA outputs\n",
    "\n",
    "\n",
    "# # NLP:\n",
    "# import spacy\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from gensim.models import word2vec\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from sklearn.decomposition import TruncatedSVD # LSA\n",
    "# from sklearn.decomposition import NMF # NMF\n",
    "# from sklearn.decomposition import LatentDirichletAllocation # LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106873, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'country', 'description', 'designation', 'points', 'price',\n",
       "       'province', 'region_1', 'region_2', 'taster_name', 'title', 'variety',\n",
       "       'winery', 'tokenized_descriptions', 'token_descr_as_string'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "winedata = pd.read_csv('../data/winedata_processed_and_tokenized.csv')\n",
    "print(winedata.shape)\n",
    "winedata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Vectorization took 8.070201873779297 seconds.\n"
     ]
    }
   ],
   "source": [
    "# vectorization on BIGRAMS using tf-idf :\n",
    "time0 = time.time()\n",
    "\n",
    "# note: we only keep 2000 features:\n",
    "tfidf_bigram_vectorizer = TfidfVectorizer(ngram_range=(1,2), # unigram and bigram (min, max)\n",
    "                               max_df=0.95, # ignore t that have a df higher than max_df (corpus-specific stopwords)\n",
    "                               min_df=10, # ignore terms that have a doc freq lower than threshold.\n",
    "                               max_features=2000, # max number of features\n",
    "                              )\n",
    "# Applying the vectorizer on the \"clean\" descriptions:\n",
    "wine_tfidf_bigram = tfidf_bigram_vectorizer.fit_transform(winedata.token_descr_as_string)\n",
    "\n",
    "# list of features\n",
    "terms_tfidf_bigram = tfidf_bigram_vectorizer.get_feature_names()\n",
    "\n",
    "# store the features in a dataframe:\n",
    "tfidf_bigram_features = pd.DataFrame(wine_tfidf_bigram.toarray(), columns=terms_tfidf_bigram)\n",
    "\n",
    "print('Done! Vectorization took', time.time()-time0, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different number of topics\n",
    "\n",
    "We run several iterations, with a different number of topics and store the results as pickles.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CHUNK TAKES TIME ! \n",
    "time0 = time.time()\n",
    "\n",
    "all_ntopics = [4,5,6,7,8,10,20,30,50]\n",
    "\n",
    "results = pd.DataFrame(all_ntopics, columns=['ntopics'], index=all_ntopics)\n",
    "\n",
    "for ntopics in all_ntopics:\n",
    "    lda = LatentDirichletAllocation(n_components=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "    # the results are stored in a dataframe, with the number of topics as index:\n",
    "    results.loc[ntopics, 'LDA'] = lda.fit(wine_tfidf_bigram)\n",
    "    \n",
    "    # we store some \"metrics\": \n",
    "    # Log Likelyhood: Higher the better\n",
    "    # Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "    results.loc[ntopics, 'LL'] = results.loc[ntopics, 'LDA'].score(wine_tfidf_bigram)\n",
    "    results.loc[ntopics, 'perplexity'] = results.loc[ntopics, 'LDA'].perplexity(wine_tfidf_bigram)\n",
    "\n",
    "print('Done! It took', time.time()-time0, 'seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of results:\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot likelihood and perplexity:\n",
    "p, axes = plt.subplots(1, 2, figsize=(16,5))\n",
    "\n",
    "p = sns.lineplot(x=\"ntopics\", y='LL', data=results, ax=axes[0])\n",
    "axes[0].title.set_text('LDA: Log Likelihood is decreasing with number of topics')\n",
    "p.set(xlabel='Number of Topics', ylabel='Log Likelihood')\n",
    "\n",
    "p = sns.lineplot(x=\"ntopics\", y='perplexity', data=results, ax=axes[1])\n",
    "axes[1].title.set_text('LDA: Perplexity is increasing with number of topics')\n",
    "p.set(xlabel='Number of Topics', ylabel='Perplexity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE ALL THESE OUTPUTS !!!\n",
    "\n",
    "for ntopics in all_ntopics:\n",
    "    # Save to file:\n",
    "    pkl_filename = '../data/pickle_LDA_' + str(ntopics) + 't.pkl'\n",
    "    with open(pkl_filename, 'wb') as file:\n",
    "        pickle.dump(results.loc[ntopics, 'LDA'], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the plots !\n",
    "\n",
    "! takes time to run too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[4, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[5, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[6, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[7, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[8, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[10, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[20, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[30, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 topics:\n",
    "pyLDAvis.sklearn.prepare(results.loc[50, 'LDA'], wine_tfidf, tfidf_vector, mds='PCoA') # or mds='mmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
